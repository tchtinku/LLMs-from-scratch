{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chapter 3: Coding Attention Mechanisms\n",
    "###### Packages that are being used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This chapter covers attention mechanisms, the engine of LLMs:\n",
    "\n",
    "#### 3.1 The problem with modeling long sequences\n",
    "###### No code in this section\n",
    "###### Translating a text word by word isn't feasible due to the differences in grammatical structures between the source and target languages:\n",
    "\n",
    "###### Prior to the introduction of transformer models, encoder-decoder RNNs were commonly used for machine translation tasks\n",
    "###### In this setup, the encoder processes a sequence of tokens from the source language, using a hidden state—a kind of intermediate layer within the neural network—to generate a condensed representation of the entire input sequence:\n",
    "\n",
    "#### 3.2 Capturing data dependencies with attention mechanisms\n",
    "###### No code in this section\n",
    "###### Through an attention mechanism, the text-generating decoder segment of the network is capable of selectively accessing all input tokens, implying that certain input tokens hold more significance than others in the generation of a specific output token:\n",
    "###### Self-attention in transformers is a technique designed to enhance input representations by enabling each position in a sequence to engage with and determine the relevance of every other position within the same sequence\n",
    "\n",
    "#### 3.3 Attending to different parts of the input with self-attention\n",
    "##### 3.3.1 A simple self-attention mechanism without trainable weights\n",
    "###### This section explains a very simplified variant of self-attention, which does not contain any trainable weights\n",
    "###### This is purely for illustration purposes and NOT the attention mechanism that is used in transformers\n",
    "###### The next section, section 3.3.2, will extend this simple attention mechanism to implement the real self-attention mechanism\n",
    "###### Suppose we are given an input sequence  to \n",
    "######   -> The input is a text (for example, a sentence like \"Your journey starts with one step\") that has already been converted into token embeddings as described in chapter 2\n",
    "######   -> For instance,  is a d-dimensional vector representing the word \"Your\", and so forth\n",
    "###### Goal: compute context vectors  for each input sequence element  in  to  (where  and  have the same dimension)\n",
    "###### A context vector  is a weighted sum over the inputs  to \n",
    "######   The context vector is \"context\"-specific to a certain input\n",
    "######   -> Instead of  as a placeholder for an arbitrary input token, let's consider the second input, \n",
    "######   -> And to continue with a concrete example, instead of the placeholder , we consider the second output context vector, \n",
    "######   -> The second context vector, , is a weighted sum over all inputs  to  weighted with respect to the second input element, \n",
    "######   -> The attention weights are the weights that determine how much each of the input elements contributes to the weighted sum when computing \n",
    "######   ->  In short, think of  as a modified version of  that also incorporates information about all other input elements that are relevant to a given task at hand"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
